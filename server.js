import express from 'express';
import cors from 'cors';
import OpenAI from 'openai';

const app = express();
app.use(cors());
app.use(express.json());
app.use(express.static('.')); // Ð´Ð»Ñ ÑÑ‚Ð°Ñ‚Ð¸ÐºÐ¸ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´Ð°

// Ð‘ÐµÑ€Ñ‘Ð¼ ÐºÐ»ÑŽÑ‡ OpenAI Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° OpenAI
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

// PORT Ð´Ð»Ñ Render
const PORT = process.env.PORT || 3000;

// API endpoint Ð´Ð»Ñ Ð¿Ð¾Ð´Ð±Ð¾Ñ€Ð° ÐŸÐš
app.post('/api/build', async (req, res) => {
    const { budget, gpu, cpu, tasks } = req.body;

    const prompt = `
ÐŸÐ¾Ð´Ð±ÐµÑ€Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ ÑÐ±Ð¾Ñ€ÐºÑƒ ÐŸÐš.
Ð‘ÑŽÐ´Ð¶ÐµÑ‚: ${budget} Ñ€ÑƒÐ±.
Ð’Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ð°: ${gpu}
ÐŸÑ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€: ${cpu}
ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ: ${tasks}

Ð’Ñ‹Ð²ÐµÐ´Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ÑƒÑŽÑ‰Ð¸Ñ…: CPU, GPU, ÐºÑƒÐ»ÐµÑ€, Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð½ÑÐºÐ°Ñ Ð¿Ð»Ð°Ñ‚Ð°, ÐºÐ¾Ñ€Ð¿ÑƒÑ, Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ, Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒ, Ð±Ð»Ð¾Ðº Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ñ Ð¸ Ñ‚.Ð´.
Ð£ÐºÐ°Ð¶Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ðµ Ñ†ÐµÐ½Ñ‹ Ð² Ñ€ÑƒÐ±Ð»ÑÑ… Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð°.
Ð¡Ð´ÐµÐ»Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚ ÑƒÐ´Ð¾Ð±Ð½Ñ‹Ð¼ Ð´Ð»Ñ Ñ‡Ñ‚ÐµÐ½Ð¸Ñ, Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÐºÐ°Ð¶Ð´Ð¾Ðµ Ð¿Ð¾Ð»Ð½Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð½Ð¾Ð²Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸.
`;

    try {
        // Ð—Ð°Ð¿Ñ€Ð¾Ñ Ðº Ð¼Ð¾Ð´ÐµÐ»Ð¸ OpenAI
        const completion = await openai.chat.completions.create({
            model: "gpt-3.5-turbo",
            messages: [{ role: "user", content: prompt }],
            temperature: 0.7,
            max_tokens: 600
        });

        const text = completion.choices[0].message.content;
        res.json({ result: text });

    } catch (err) {
        console.error(err);
        res.status(500).json({ result: "âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ." });
    }
});

// Ð—Ð°Ð¿ÑƒÑÐº ÑÐµÑ€Ð²ÐµÑ€Ð°
app.listen(PORT, () => {
    console.log(`ðŸš€ Server running on port ${PORT}`);
});
