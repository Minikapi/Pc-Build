import express from 'express';
import cors from 'cors';
import OpenAI from 'openai';

const app = express();
app.use(cors());
app.use(express.json());
app.use(express.static('.')); // Ð¾Ñ‚Ð´Ð°Ñ‘Ð¼ Ñ„Ñ€Ð¾Ð½Ñ‚ÐµÐ½Ð´

// Ð‘ÐµÑ€Ñ‘Ð¼ ÐºÐ»ÑŽÑ‡ OpenAI Ð¸Ð· Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
if (!OPENAI_API_KEY) console.error("âŒ OPENAI_API_KEY Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½!");

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

const PORT = process.env.PORT || 3000;

app.post('/api/build', async (req, res) => {
  const { budget, gpu, cpu, tasks } = req.body;

  const prompt = `
ÐŸÐ¾Ð´Ð±ÐµÑ€Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ ÑÐ±Ð¾Ñ€ÐºÑƒ ÐŸÐš.
Ð‘ÑŽÐ´Ð¶ÐµÑ‚: ${budget} Ñ€ÑƒÐ±.
Ð’Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ð°: ${gpu}
ÐŸÑ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€: ${cpu}
ÐÐ°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ: ${tasks}

Ð’Ñ‹Ð²ÐµÐ´Ð¸ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ÑƒÑŽÑ‰Ð¸Ñ…: Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€, Ð²Ð¸Ð´ÐµÐ¾ÐºÐ°Ñ€Ñ‚Ð°, ÐºÑƒÐ»ÐµÑ€, Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð½ÑÐºÐ°Ñ Ð¿Ð»Ð°Ñ‚Ð°, ÐºÐ¾Ñ€Ð¿ÑƒÑ, Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¿Ð°Ð¼ÑÑ‚ÑŒ, Ð½Ð°ÐºÐ¾Ð¿Ð¸Ñ‚ÐµÐ»ÑŒ, Ð±Ð»Ð¾Ðº Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ñ Ð¸ Ð´Ñ€.
Ð£ÐºÐ°Ð¶Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð½Ñ‹Ðµ Ñ†ÐµÐ½Ñ‹ Ð² Ñ€ÑƒÐ±Ð»ÑÑ….
ÐšÐ°Ð¶Ð´Ð¾Ðµ Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ Ñ Ð½Ð¾Ð²Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸.
`;

  try {
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo", // Ð¼Ð¾Ð¶Ð½Ð¾ Ð·Ð°Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ð½Ð° "gpt-4o" ÐµÑÐ»Ð¸ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾
      messages: [{ role: "user", content: prompt }],
      temperature: 0.7,
      max_tokens: 1500 // ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð»Ñ Ð¿Ð¾Ð»Ð½Ð¾Ð³Ð¾ ÑÐ¿Ð¸ÑÐºÐ°
    });

    const text = completion.choices[0].message.content;
    res.json({ result: text });
  } catch (err) {
    console.error("âŒ Server error:", err);
    res.status(500).json({ result: "âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐµÑ€Ð²ÐµÑ€Ð°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ." });
  }
});

app.listen(PORT, () => {
  console.log(`ðŸš€ Server running on port ${PORT}`);
});
